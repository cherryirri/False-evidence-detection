# False-evidence-detection
The most challenging problem I personally solved in this project was identifying and addressing the overfitting that occurred when we initially trained our image tampering model on a dummy dataset. The model appeared to perform perfectly during training, which clearly indicated that it was memorising the data rather than learning meaningful forensic features. To validate this, I tested the model on the real CASIA dataset and confirmed that its behaviour changed significantly, proving that the dummy dataset results were not reliable. I then improved the overall pipeline by refining the preprocessing steps, adding more realistic image augmentations, and analysing detailed evaluation outputs such as ROC curves, confusion matrices, and Grad CAM visualisations. These steps helped the model learn more general patterns and behave more consistently on real examples. By detecting the overfitting early and validating the approach with a real world dataset, I ensured that the final system was dependable and meaningful rather than artificially perfect.
